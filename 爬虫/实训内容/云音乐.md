# 爬取网易云音乐
```
# 爬取网易云音乐
# from urllib.request import *        # urllib 是一个文件夹，request是一个模块
# from lxml import etree
# import time
# # from fake_useragent import UserAgent        # 插件，获取报头的一个库：'User-Agent': ua.random  'User-Agent': 'ua.chrome'
# # ua = UserAgent()
#
# url = "https://music.163.com/artist?id=2116"
# URL2 = "https://music.163.com/song/media/outer/url?id="
#
# headers = {  # 请求报头
#     'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.86 Safari/537.36'
#     # 'User-Agent': ua.random
#     # 'User-Agent': 'ua.chrome'
# }
#
# req = Request(url,headers=headers)       # urllib的请求对象  urlopen（url|RequestObject）
#
# with urlopen(req) as html:
#     text = html.read().decode('utf-8')
#
# # 获取
# doc = etree.HTML(text)
# # print(text)     # 反爬机制，没有给服务器发送东西，就会被当作爬虫
#
# songs = doc.xpath("//ul[@class='f-hide']/li/a/text()")
# links = doc.xpath("//ul[@class='f-hide']/li/a/@href")
# ids = [ link[9::] for link in links]
# # print(list(zip(songs,ids)))
#
#
# for sid,title in zip(ids,songs):
#     time.sleep(1)
#     req2 = Request(URL2 + str(sid),headers=headers)
#     with urlopen(req2) as html:
#         urlretrieve(html.geturl(),'songs/%s.mp3'%title)     # 下载资源的函数
#         print("songs/%s.mp3 下载完成"%title)
```